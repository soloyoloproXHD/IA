I. Introducción
Entre los grandes desafíos y oportunidades que ofrece la inteligencia artificial (IA) están los aportes de su técnica a la medicina y al cuidado de la vida. Son incontables los beneficios que se pueden aplicar, desde el conocimiento e investigación del cuerpo humano hasta los elementos exógenos que pueden ofrecer una calidad de vida impensable hasta hace poco tiempo, entre los que se encuentran los robots, que pueden facilitar el movimiento de articulaciones humanas que carecían de esta facultad. Y, al mismo tiempo que al servicio de la calidad de vida, la inteligencia artificial y la robótica, inevitablemente, colaboran también en el nuevo modo de comprender científica y técnicamente no sólo el final de la vida, sino también el modo con el que se percibe el contexto del sufrimiento en la persona humana. Si en el pasado remoto el problema de la muerte acontecía ante el destino y definitividad de la ruptura entre la sustancia y la materia; en el presente, estas determinaciones han dado paso a las exigencias materiales de la limitación de la corporalidad, que afecta a la tolerancia al dolor y la limitación psicológica para dar, o negar, sentido al sufrimiento. El dolor físico, el sufrimiento espiritual y la concreción de la muerte ¿pueden ser aliviados con esta nueva tecnología médica?

La imponderable realidad del dolor, del sufrimiento y de la muerte, ha buscado respuestas fundamentalmente a través de códigos religiosos, éticos y, como no, también jurídicos. Esta fue la necesidad de la exigencia del juramento hipocrático que ha regulado los objetivos de la profesión médica desde la antigua Grecia hasta nuestros días; si bien, lo que parecía inalterable, a medida que los nuevos valores impregnan la sociedad contemporánea, también ha afectado a la comprensión de la enfermedad, el dolor y de la muerte, introduciendo cambios axiológicos en los que la consideración preponderante de la autonomía del paciente en la valoración ética de los tratamientos y sus finalidades se ha impuesto sobre los criterios externos, ya fueran de matriz religiosa, jurídico-ética o incluso médica[1].

Desde esta perspectiva, los promotores de la eutanasia han pretendido incoar la necesidad de su regulación, de modo que, más que una mera despenalización, el legislador ha tratado de ofrecerla a la sociedad contemporánea como la única respuesta a esa triple “amenaza” que suponen la enfermedad, el sufrimiento y la muerte a nuestra cultura contemporánea, que se halla huera de resortes con los que hacer frente a la inexorabilidad del tiempo y el deterioro biológico que genera en la condición humana (Beltrán Aguirre, 2021, 156)[2]. A pesar de ello, lo más significativo de nuestros días es que estas regulaciones de origen parlamentario, formalmente constitucionales de democracias liberales, una vez que se han consensuado en la sede política oportuna, dejan el peso moral, el control administrativo y la ejecución de esa única respuesta en las manos de los profesionales sanitarios, obviando otras alternativas que la profesión médica ya había implantado, como pueden ser los tratamientos paliativos al dolor y la colaboración multidisciplinar para ofrecer dinamismos espirituales que sostuvieran la procaz fuerza del sufrimiento, ya que la muerte, como tal, ni tan siquiera el transhumanismo ha logrado, hasta el momento, frenarla.

Así lo corrobora la opción de la Ley Orgánica de Regulación de la Eutanasia 3/2021 de 24 de marzo[3], que opta, como todas las regulaciones de la eutanasia en el Derecho comparado, por un modelo medicalizado en la prestación de la ayuda para morir (PAM), incluido en la cartera común de servicios del Sistema Nacional de Salud (art. 13.1 LORE), en la que, ante la eficacia del “tratamiento” que genera la muerte del paciente, no controla nadie más que el médico y la Comisión de Garantías y Evaluación aprobada por la Comunidad Autónoma correspondiente, que toma referencia del caso particular exclusivamente mediante los informes.

Me sorprende que no está previsto, ni en la LORE ni en ninguna otra norma reguladora de la eutanasia a nivel mundial, el control judicial, del Ministerio Fiscal o alguna otra intervención de los órganos de inspección sanitaria en los procedimientos para ofrecer la PAM, ni tan siquiera en los casos en los que la Comisión hubiera detectado alguna anomalía, cuestión que solventaría la delegación sanitaria pertinente. En todo caso, quedaría una inspección ex post-facto, que carece de sentido para el finado. Es decir, la medicalización de la prestación para la ayuda morir tiene su ámbito lógico en las instituciones sanitarias, pero se echa en falta un procedimiento abreviado o urgente en el que los controles y garantías de la vida de las personas pueda estar protegida por quienes constitucionalmente están habilitados para ello. No se comprende cómo, por ejemplo, para el necesario proceso de incapacitación de una persona se requiera este control, y para la muerte, aun cuando fuera requerida por el propio paciente, no exista.

Los códigos éticos que han regulado la lex artis repudiaron la eutanasia como respuesta a la enfermedad y al sufrimiento, precisamente, porque consideraban que la muerte era la derrota de la medicina en una batalla épica, en la que el argumento de la compasión, que aceleraba el momento de la muerte, no podía ser alegado ni tan siquiera a solicitud del propio paciente, como refiere el juramento hipocrático: «No daré a nadie medicamento mortal, por mucho que me lo soliciten, ni tomaré iniciativa alguna de este tipo». Sin embargo, la federación mundial de las sociedades que propician el derecho a morir propugna que ese juramento hipocrático es perfectamente compatible con el principio de la beneficencia médica porque, con la eutanasia se alivia el dolor (Torre Díaz, 2019, 23).

El argumento del mercy-killing es, junto con el de la autonomía de la voluntad, el que sociológicamente tiene un peso mayor para la regulación e implantación de la eutanasia (Wood Mak /Elwyn, 2005, 345). Por eso, la presumible resistencia inicial de la profesión médica a la aplicación de la eutanasia en los términos que establece la nueva regulación española tiene un doble camino para ser vencida. El primero es que la profesión médica asuma, como lo ha hecho la sociedad, la necesidad de la eutanasia, pues cada vez está más inclinada a percibir cualquier tipo de sufrimiento como el adversario de la humanidad. Presumo, lamentablemente, que requerirá como mucho una sola generación médica más para que esta profesión acepte acríticamente los envites morales que suscita la eutanasia. El segundo camino para superar el hiato de estimación entre la profesión médica y la sociedad es la implantación exponencial de las nuevas tecnologías, inteligencia artificial y/o robótica, para que suplanten o sustituyan los inconvenientes que la ordenación jurídica ha depositado en las manos de los profesionales sanitarios. Esta aportación quiere afrontar esta última perspectiva.

II. Eutanasia e inteligencia artificial
Entre las primeras labores que la LORE exige a la profesión médica está la valoración, en primer lugar, por el médico responsable de las condiciones del llamado contexto eutanásico del paciente que solicita la eutanasia. El contexto eutanásico es un concepto definido en la LORE como: «una situación de padecimiento grave, crónico e imposibilitante, o de enfermedad grave e incurable, padeciendo un sufrimiento insoportable que no puede ser aliviado en condiciones que considere aceptables» (Preámbulo, § 1). Una labor que, como señala el Comité de Bioética, es muy compleja debido a las circunstancias subjetivas, además de los parámetros objetivos, que pueden ser registrados biométricamente (CBE, 2021, 15).

Para ayudar a esa valoración, y en principio sin sustituir el criterio humano del médico responsable, la Inteligencia Artificial puede desarrollar algoritmos que relacionen los datos objetivos de la salud del paciente con los subjetivos, e interrelacionarlos para determinar tanto los umbrales del sufrimiento humano tolerables como los contextos sociales en los que se desarrolla la vida del paciente, de forma que puedan tomarse en consideración, además, los datos familiares, el posible alejamiento (físico) de los hijos, y, por supuesto, ¿por qué dudarlo?, coste sanitario de los tratamientos que se aplican a los enfermos. De hecho, un reciente estudio del CSIC y algunas universidades americanas ha propuesto el uso de indicadores médicos para determinar la esperanza de vida de las personas a partir de los 65 años[4], lo que acerca la posibilidad de ese algoritmo a la posibilidad de calibrar el contexto eutanásico de los pacientes.

En efecto, el acopio de los datos obtenidos en las memorias médicas de los pacientes presupone un acervo documental que un sistema informático o IA puede archivar, estructurar, organizar y utilizar con una capacidad muy superior a la humana (Pérez Luño, 2021, 41) de modo que la máquina o algoritmo puede hacerse cargo de la masa arbitraria de los datos del historial, desarrollando una mayor eficacia computacional gracias al aprendizaje automático (Garrido Martín, 2021, 156). No es algo nuevo, la hipótesis de que, en la relación entre el médico y la máquina que gestione los datos de la vida del paciente, la máquina diagnostique con mayor precisión y sugiera el tratamiento más adecuado, ya lo había previsto el pionero de la nefrología contemporánea (Schwartz, 1970, 1259). De esta manera, el problema de desconfianza que genera la eutanasia para la profesión médica, porque la considera una perversión del principio de beneficencia y no es un acto médico (CACM, 2022), podría “solucionarse” con una aplicación matemática que resolviera el problema de conciencia del médico, que dejara “impoluta” la confianza de su profesión, trasladando la gestión de la confianza al ámbito aparentemente neutro de un algoritmo.

Ante esta hipótesis, percibo tres problemas: a) cómo puede ser usada éticamente este algoritmo en el ámbito médico (Savini Nicci / Vetrugno, 2020, 607) para determinar si una persona es susceptible, o no, de recibir como tratamiento la PAM, es decir, si es posible que, dado que el criterio de discernimiento médico plantea problemas éticos para el profesional (médico responsable), el algoritmo puede, y hasta dónde, definir con mayor seguridad el estado del contexto eutanásico del paciente, para luego, pasar su valoración a la Comisión de Garantías; b) el siguiente problema está conectado con el anterior según el procedimiento de la LORE, pues me pregunto si esta Comisión puede llegar a conceder un valor superior al resultado que establezca el algoritmo o deberá confiar más en la capacidad valorativa del médico responsable; y c) si, en un futuro no contemplado por la LORE, el algoritmo puede llegar a sustituir, en este ámbito tan delicado, no sólo a la figura del médico responsable, sino a la propia persona solicitante de la PAM, imponiéndole la eutanasia por motivos utilitaristas.

Es decir, planteo, grosso modo, cómo una máquina u algoritmo puede convertirse en un agente normativo, cuya decisión puede tener un impacto ético (Anderson, 2011, 7) tan explícito que pueda no sólo decidir qué personas pueden recibir la PAM, sino que tenga la capacidad de condicionar, con el poder de sus datos, incluso el informe que la Comisión de Garantía determine, generando así una máquina con una “moralidad artificial” (Ferreira, 2021, 103), la cual pueda afectar la vida de los enfermos que han solicitado la eutanasia. Aunque, personalmente prefiero, como Asimov, descartar la hipótesis de que pueda llegar el día en que la máquina esté tan perfeccionada que no se necesite siquiera el consentimiento del paciente (Asimov, 1942).

Las condiciones del uso ético de la IA para determinar el contexto eutanásico en una persona que haya solicitado la eutanasia supone un problema muy complejo, pues mientras que la tecnología de la IA se basa en datos, y estos datos están impresos en el historial médico de la persona, la persona en ese contexto eutanásico debe ser considerada con un plus respecto a los mismos datos que ella misma y su historial médico ha registrado. La persona enferma es independiente de su propio historial médico, que debe ser cuidado no sólo por exigencia del secreto profesional, sino porque revela la intimidad de la persona en la que están en juego valores como las relaciones familiares, y de modo anexo, otros datos de singular importancia como el de su capacidad económica.

Caso de implantarse este modelo, tendrá que someterse al ecosistema de confianza propio del marco regulador de la IA en Europa que protege los derechos fundamentales (COM, 2020, 65 final), especialmente en lo relativo a la protección de datos, y, por ende, en esos datos tan complejos que pueden determinar el contexto eutanásico. No obstante esta precisa regulación no deja de tener algunos obstáculos (Moral Soriano, 2021, 243), como los riesgos imprevistos que puedan surgir en la incorporación y elaboración de los datos en un mismo procesador, la incertidumbre en la imputación de responsabilidades, médicas o administrativas, y por supuesto, el más grave de todos a mi juicio, la introducción de determinados sesgos algorítmicos que, consciente o inconscientemente, pueden definir un resultado con apariencia objetiva, pero que también pueden llevar implícitos factores de exclusión y/o discriminación (Belloso, 2022, 45).

En esta hipótesis, la sustitución del algoritmo por la valoración del médico responsable, a fuer de una mayor precisión en la elaboración de los datos (Llano Alonso, 2018, 133) y falta de arbitrariedad, gracias a la ausencia de sesgos discriminatorios, plantea un subsiguiente problema: ¿qué hacer con el proceso deliberativo entre el médico responsable y la persona solicitante, si es mucho más efectivo el algoritmo? ¿podría ese proceso deliberativo llevarse a cabo por sistemas de IA como Siri o Alexa, preparados para ello? Y, una vez concluido el plazo para el proceso deliberativo, ¿quién debería firmar el documento de comunicación dirigido a la Comisión de Garantías? Ante estas preguntas, emergen otras de carácter más general: ¿Quién o qué es ese algoritmo, quién es su responsable?

Como puede deducirse, una tecnología de este calibre, que utilizara una tecnología de tipo predictivo que pudiera conducir nada menos que a la prestación de ayuda a morir, debería entenderse de alto riesgo, de cuya regulación entiende la Resolución del Parlamento Europeo de 3 de mayo de 2022 sobre la inteligencia artificial (Parlamento Europeo, 2022), que destaca que, en el sector sanitario, entre los requisitos éticos exigibles están: la necesidad de la supervisión humana constante (nº 22); la IA sea un instrumento, no un sustituto de los profesionales sanitarios (nº 240); impide a las compañías de seguros y análogas al acceso a la información almacenada (nº 242), pide a la Comisión que promueva la investigación sobre los sesgos (nº 246).

De esta manera, parece que la respuesta a estas preguntas es conclusiva desde la Unión Europea, no así en los marcos regulatorios de Estados Unidos o China, pues determina que en cualquier caso la labor del médico responsable y de la Comisión de Garantías deberá ser imprescindible porque no puede ser sustituida por ninguna aplicación de IA, lo que facilita su incardinación en un sistema propio de garantías en el Estado de Derecho ante los riesgos y los sesgos que pueden generarse en una regulación más marcada por los principios utilitaristas (Wisner Gluskso, 2022, 544). Sin embargo, no podemos descartar que, como la esperanza de vida se ha prolongado y la calidad de vida también (LORE, preámbulo § 1), puedan ser en un sombrío futuro, las mismas administraciones públicas, aquellas que debieran regular ese sistema de valoración del contexto eutanásico, las que lleguen a introducir los sesgos necesarios para que el resultado fuera favorable a la aplicación de la PAM, sin la debida diligencia de respeto al Derecho a la vida de la persona vulnerable (Iturmendi Morales, 2021, 90):

es probable que según avance el desarrollo tecnológico de la IA, aún surjan nuevos escenarios de riesgos escalofriantes que atenten a los principios éticos de la IA en detrimento de los valores de respeto a la dignidad humana, libertad, democracia, igualdad, no discriminación, Estado de Derecho y respeto de los derechos humanos.

III. Aplicación de eutanasia por robótica
La comunidad ético-médica está dividida por el recurso a la objeción de conciencia en todo el proceso deliberativo con el paciente, protagonizado por los médicos responsables, consultores, equipos sanitarios y la Comisión de Garantías hasta la aplicación, propiamente dicha, de la PAM. Así, por ejemplo, difieren el informe posibilista del Comité de Bioética de España, que aconseja el deber moral del médico responsable al acompañamiento al paciente en el momento de deliberación (CBE, 2021, 15) y, por otro lado, la Asociación Española de Bioética y Ética Médica insiste en la necesidad de no colaborar en ninguno de los procesos de la PAM, y formalizar la objeción de conciencia a la ley por cualquier profesional sanitario (AEBI, 2021, 365-366).

Ante estas dudas éticas, ¿no sería posible la delegación en un robot que, con apariencia de médico, solventara con el procesador de datos de IA todo el proceso deliberativo? Si la misma LORE trata, no sólo de regular, sino de facilitar el proceso de la ayuda a morir basada en la misma autonomía de la voluntad del paciente que ha decidido terminar sus días, aunque la ley quiera mostrar garantías, ¿no bastaría, acaso, un robot que reprodujera la acción del profesional médico y le descargara toda objeción de conciencia trasladándola simplemente a un algoritmo? Pero, en ese caso, ¿no podría devenir la intervención robótica en un problema de manipulación de esa autonomía?

La profesora Rosalie Waelen, en el Instituto Ratheneau, destaca que es posible que el robot o la IA introduzca elementos de manipulación, que llama “negligentes”. Esta manipulación, en el caso de la eutanasia, pretendería influir sobre la libertad de elección del paciente gracias a la asimetría del conocimiento que tuviera el robot extraído del historial médico. Así, es posible que, en cualquier momento, los promotores del algoritmo pudieran forzar a aceptar unos datos o una decisión que, el paciente por él mismo, sin esa manipulación, nunca hubiera aceptado (Waelen, 2022). El uso de la IA o de un robot que formulara todo el proceso de la PAM, resultaría muy fácil la hipótesis de este tipo de manipulación negligente, ¿por qué? La misma Waelen ofrece una respuesta cuando afirma que ante las decisiones complejas, la robótica programada con la IA ofrece una respuesta sencilla, hasta el punto de que puede eliminar la deliberación personal gracias a la confianza que genera la eficacia de los datos proporcionados.

En efecto, frente a la medicina tradicional, si el Sistema Nacional de Salud introdujera la deliberación por medio de la robótica en beneficio de esa eficacia médica, también cabe la amenaza de que junto a los datos de la salud de la persona (contexto eutanásico), se cruzara también un análisis con los datos del coste de la vida, de los tratamientos, de la previsible esperanza de vida, de las exigencias vitales de los acompañantes, o del tipo de deterioro que conduciría la prolongación de la vida. De modo que al mismo tiempo que, efectivamente, la robótica pudiera analizar la compleja decisión de la evaluación clínica, también pudiera servir para abrumar al paciente para que aceptara definitivamente la eutanasia. Pero no se trata solo de la eficacia de los números que puede arrojar el informe elaborado por el robot, sino que también, en ese momento tan trascendental para la vida de una persona, incluso si ella deseara terminar con su vida, la calidad de los cuidados se requiere la presencia de una persona, tal y como se advierte en el informe Human rights in the robot age del Instituto Ratheneau, en el que se destaca el potencial de un nuevo “derecho humano” definido como el derecho a un contacto humano digno, especialmente en el cuidado de los enfermos y personas mayores, pues el contacto con los robots no puede compensar la falta de contacto humano, y más en las circunstancias del llamado contexto eutanásico, alegando que el cuidado de las personas es una característica clave de la cultura humana, puesto que reemplazar el factor humano con los robots podría deshumanizar la práctica del cuidado (Van Est / Gerritsen / Kool, 2017, 44-45).

Así pues, ante la imposibilidad ética para delegar en ese algoritmo, o en la robótica programada convenientemente para la deliberación en el contexto eutanásico, mi pregunta se dirige entonces, a la hipótesis de una fuera un sistema robótico el que, en el caso de que la objeción de conciencia fuera unánime en el centro del Sistema Nacional de Salud, ejecutara prácticamente eutanasia ¿cabría la posibilidad ética y jurídica de que la ejecución de la PAM fuera llevada a cabo por un robot, lo que no se contempla en la LORE? Y, subsiguientemente, ¿no sería posible la mercantilización de un producto robótico que solventara la necesidad de recurrir al Sistema Nacional de Salud, sin tener que iniciar todo el proceso deliberativo y de garantías?

En primer lugar, habría que destacar la complejidad para ofrecer una definición jurídicamente cualificada de los robots ya que una de sus características es la capacidad de sus productores para escaparse a la normativa, a pesar de que grupos de investigación multidisciplinares y trasnacionales pretendan regularlo como Robolaw, de modo que este ámbito sigue ofreciendo una visión proyectiva o futurista en el que la realidad robótica parece estar cómoda, sin el intervencionismo regulatorio pertinente, cuánto más cuando la mayoría de los productos en el mercado proceden de países que prescinden de la pretensión regulatoria en torno a la defensa de valores como la dignidad humana o la salud que tiene, por ejemplo, la Unión Europea (Llano Alonso, 2018, 139).

No obstante, a pesar de ello, hay quien apunta algunas características o patrones sobre lo que podemos definir la realidad robótica como:

un objeto mecánico que capta el exterior, que lo percibe, y a su vez, actúa positivamente en mundo (…) bajo el paradigma de ‘sentir-pensar-actuar’ (…) dispositivos fabricados por el hombre con tres componentes seminales: a) sensores que vigilan el entorno y detectan cambios en él, b) procesadores o inteligencia artificial que deciden cómo responder y c) actuadores que operan sobre el entorno de manera que reflejen las decisiones (Barrio Andrés, 2021, 33).

Ahora bien, al menos por ahora, esas “capacidades” sensitivas, procesadoras y actuadoras no son absolutamente independientes del software creado por el hombre, por lo que el problema de la autoconciencia no lo planteo aún, pero sí es factible la posibilidad de que en la programación del producto robótico, pudieran introducirse elementos para realizar actos ilícitos y eludir la responsabilidad para imputárselas al robot (Moravec, 1988, 48-49), entre los cuales ilícitos estaría el que un robot pudiera aplicar la PAM ajeno al procedimiento reglado por la LORE, como si se implantase comercialmente un proyecto de robot como la fake news de SeppuKuma[5], un robot que, supuestamente, fue creado por ingenieros de la Japan Society for Dying with Dignity y la Orient Industry Company, para ejecutar la PAM sin ninguna referencia a regulación establecida.

IV. Conclusiones
Las condiciones sociológicas contemporáneas que sustentan la necesidad de una regulación de la eutanasia está determinada por los avances técnico-científicos que han prolongado la esperanza de vida, la capacidad de movilidad humana, que se explicita en una experiencia de autodeterminación y una calidad de vida más exigente, la desestructuración de la célula familiar que conlleva una percepción mayor de la soledad, la capacidad cada vez más reducida de los recursos públicos por el aumento de la población más vulnerable y, a pesar de los avances, la presencia ineluctable del dolor y el sufrimiento en el hombre.

La regulación de este derecho en los ordenamientos jurídicos, donde ha sido aprobada, ha depositado la responsabilidad en la profesión médica, la cual, tiene, por su capacitación técnica y humana, no sólo el monopolio del ejercicio de la medicina, sino, además, su administración burocrática y de control, por lo que, la aplicación de la eutanasia también depende de ella, sin ninguna otra reserva o control externo a sus actos (salvo en lo que refiere a un control ex –post – facto).

A pesar de que los sondeos demoscópicos han advertido un creciente anhelo de este derecho subjetivo, como resultado de la ausencia de recursos para afrontar el problema del sentido del sufrimiento, la profesión médica se ha resistido a que la regulación positiva haga responsable y administradores únicos de la aplicación de un pseudo-tratamiento que no concuerda con la especificidad de su lex artis, tal y como advierten los códigos deontológicos que regulan esta profesión.

El procedimiento establecido para la aplicación de la demanda de la eutanasia requiere una valoración precisa por parte del médico responsable y de los miembros de la Comisión de Garantías. Como la profesión puede alegar objeción de conciencia y se puede paralizar el procedimiento, la Administración puede verse tentada de que ese mismo proceso pueda ser llevado adelante por medios tecnológicos, ya sean por la IA o por la robótica que valoren, describan, analicen y hasta ejecuten con mayor precisión la deseada aplicación de la eutanasia, gracias incluso a la incorporación de sesgos que pudieran favorecer la concesión administrativa de una prestación administrativa que termina con la muerte, irreversible, del paciente.

Sin embargo, como hemos visto, la legislación europea niega tal posibilidad al exigir un último recurso personal de control de garantías. Además, aunque las prestaciones sanitarias estén cada vez más desarrolladas por vía tecnológica, sin duda la exigencia de atención personal requerirá una relación médico-paciente de calidad, especialmente porque la prestación solicitada podría vulnerar los derechos fundamentales de los pacientes. Sin duda, si ya la mera exigencia de la PAM a la profesión médica vulnera el código deontológico médico, una aplicación electrónica deterioraría aún más la confianza en la profesión.

Mucho más peligrosa sería, finalmente, la incorporación de robots quirúrgicos diseñados para la aplicación de la PAM que pudieran incluso entrar en un mercado legal, que no tuvieran ningún tipo de control humano salvo la garantía del origen de su producción. Este tráfico, sin duda, alteraría la maltrecha exigencia de los principios éticos de la medicina como los de la beneficencia, no maleficencia y justicia en favor exclusivamente de una atención al de la autonomía de la voluntad.

A pesar de la legislación garantistas de la Unión Europea, preveo que la futura educación de la profesión médica y las presiones sobre la opinión pública acerca de la aplicación de la eutanasia, los instrumentos tecnológicos ocuparan cada vez una mayor presencia en la aplicación de la eutanasia, sustituyendo los criterios humanistas por otros de mayor calado utilitaristas, de manera que el plus de humanidad médica pueda rendirse a una pretensión de precisión de la tecnología, aunque hayamos demostrado su vulnerabilidad por los sesgos que también puedan influir en los procesos deliberativos en la aplicación de la eutanasia.